{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using Dask to parallel process the global mean sea level anomaly using PO.DAAC data in the cloud\n",
    "\n",
    "#### Jinbo Wang <Jinbo.Wang@jpl.nasa.gov>\n",
    "\n",
    "#### June 13, 2022\n",
    "\n",
    "This notebook demonstrates parallel computing using Dask within the AWS cloud. This code can only be ran in the AWS US-West-2. \n",
    "\n",
    "The global mean sea level is an important climate indicator. It can be calculated from the global-gridded altimetry product. In this example, we will use the gridded MEaSUREs sea surface height (SSH) Level-4 product hosted in POCLOUD. The details can be found on the product's [landing page](https://podaac.jpl.nasa.gov/dataset/SEA_SURFACE_HEIGHT_ALT_GRIDS_L4_2SATS_5DAY_6THDEG_V_JPL1812]).\n",
    "\n",
    "The gridded SSH product has 1992 files. Each file represent a 5-day mean sea surface height on a 1/6-degree grid. In this demonstration, we first show that calculating the global mean sea level from 1922 file takes 17 minutes if we use a signal thread, but 42 seconds if we use Dask with 32 workers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "#Short_name is used to identify a specific dataset in NASA Earthdata. \n",
    "short_name='SEA_SURFACE_HEIGHT_ALT_GRIDS_L4_2SATS_5DAY_6THDEG_V_JPL1812'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the handle to the AWS S3 file system\n",
    "\n",
    "PO.DAAC cloud (POCLOUD) is a part of Earthdata Cloud. The data are hosted in a S3 bucket on AWS US-West-2. \"US-West-2\" represents the AWS center in Oregon. In this case, the Direct-S3 access only works on the machines hosted in the US-West-2. \n",
    "\n",
    "**s3fs** is a pythonic file interface to S3 built on top of [botocore](https://github.com/boto/botocore). s3fs allows typical file-system style operations like cp, mv, ls, du, glob, and put/get of local files to/from S3. Details can be find on its website https://s3fs.readthedocs.io/en/latest/.  \n",
    "\n",
    "It is important that you set up the .netrc file correctly in order to enable the following *init_S3FileSystem* module. The .netrc file should be placed in your home folder. A typical .netrc file has the following content:\n",
    "```bash\n",
    "machine urs.earthdata.nasa.gov\n",
    "    login your_earthdata_username\n",
    "    password your_earthdata_account_password\n",
    " ```\n",
    " \n",
    "If you do not have or do not remember your Earthdata Login information, go [here](https://urs.earthdata.nasa.gov/users/new) to register or [here](https://urs.earthdata.nasa.gov/reset_passwords/new) to reset password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_S3FileSystem():\n",
    "    import requests,s3fs\n",
    "    creds = requests.get('https://archive.podaac.earthdata.nasa.gov/s3credentials').json()\n",
    "    s3 = s3fs.S3FileSystem(anon=False,\n",
    "                           key=creds['accessKeyId'],\n",
    "                           secret=creds['secretAccessKey'], \n",
    "                           token=creds['sessionToken'])\n",
    "    return s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use s3fs.glob to get all file names\n",
    "\n",
    "Once the s3fs file system is established, we can use 'glob' to get all file names from a collection. In this case, the collection S3 path is \n",
    "```bash\n",
    "s3://podaac-ops-cumulus-protected/SEA_SURFACE_HEIGHT_ALT_GRIDS_L4_2SATS_5DAY_6THDEG_V_JPL1812/\n",
    "```\n",
    "\n",
    "Using the following will get a list netcdf filenames: \n",
    "```\n",
    "fns=s3sys.glob(\"s3://podaac-ops-cumulus-protected/SEA_SURFACE_HEIGHT_ALT_GRIDS_L4_2SATS_5DAY_6THDEG_V_JPL1812/*.nc\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3sys=init_S3FileSystem()\n",
    "\n",
    "s3path=\"s3://podaac-ops-cumulus-protected/%s/\"%short_name\n",
    "fns=s3sys.glob(s3path+\"*.nc\")\n",
    "print(fns[0])\n",
    "#Set the time stamps associated with the files\n",
    "time=pd.date_range(start='1992-10-02',periods=len(fns),freq='5D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %i files.'%len(fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=xr.open_dataset(s3sys.open(fns[0]))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualte the grid area \n",
    "\n",
    "The grid area associated with each grid is uniform in longitude. We only need to calculate the grid area for one longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(lats):\n",
    "    # Modules:\n",
    "    from pyproj import Geod\n",
    "    # Define WGS84 as CRS:\n",
    "    geod = Geod(ellps='WGS84')\n",
    "    dx=1/12.0\n",
    "    c_area=lambda lat: geod.polygon_area_perimeter(np.r_[-dx,dx,dx,-dx], lat+np.r_[-dx,-dx,dx,dx])[0]\n",
    "    out=[]\n",
    "    for lat in lats:\n",
    "        out.append(c_area(lat))\n",
    "    return np.array(out)\n",
    "\n",
    "ssh_area=np.repeat(area(d.Latitude.data).reshape(1,-1),d.Longitude.size,axis=0)\n",
    "gm=ssh_area.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the global mean SSHA\n",
    "\n",
    "Use the area to calculate the area associated with each grid. The global mean SSH is calculated as follows. \n",
    "\n",
    "$SSH_{mean} = \\sum \\eta(\\phi,\\lambda)*A(\\phi)$, where $\\phi$ is latitude, $\\lambda$ is longitude, $A$ is the area of the grid at latitude $\\phi$, and $\\eta(\\phi,\\lambda)*A(\\phi)$ is the SLA at $(\\phi,\\lambda)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(fn_s3,s3sys):\n",
    "    with xr.open_dataset(s3sys.open(fn_s3))['SLA'] as d:\n",
    "        dout=((d*ssh_area).sum()/(d/d*ssh_area).sum()).values\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_mean(fns[0],s3sys) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate use a single thread\n",
    "\n",
    "Benchmark: using a sigle thread takes about 17 min to calculate all 1922 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result=[]\n",
    "\n",
    "for fn in fns[:10]:\n",
    "    result.append(global_mean(fn,s3sys) )\n",
    "plt.plot(time[:10],np.array(result).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us try Dask\n",
    "\n",
    "Benchmark: It took 43 seconds to go through the 1922 files using 32 workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed,compute\n",
    "client = Client(n_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result=[]\n",
    "\n",
    "for fn in fns:\n",
    "    result.append(delayed(calc_mean)(fn,s3sys) )\n",
    "\n",
    "output=np.array(compute(result)).squeeze()\n",
    "\n",
    "plt.plot(time,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
