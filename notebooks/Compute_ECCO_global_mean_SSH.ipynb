{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Dask parallel compute with POCLOUD (US-WEST-2)\n",
    "## Compute global mean ocean SSH from ECCO Version 4 Release 4\n",
    "\n",
    "Written by Ian Fenty, revised by Jinbo Wang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# used the dask-labextension to start the LocalCluster\n",
    "client = Client(\"tcp://127.0.0.1:65532\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dask.distributed import get_worker\n",
    "from dask import delayed\n",
    "\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import s3fs\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from itertools import repeat\n",
    "from os.path import expanduser, basename, isfile, isdir, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_GMSL(SSH, grid_area, total_grid_cell_area):\n",
    "    ''' Compute the global mean '''\n",
    "    GMSL = (SSH * grid_area).sum(dim=['latitude','longitude']) / total_grid_cell_area\n",
    "    GMSL = GMSL.compute()\n",
    "    return GMSL\n",
    "def compute_GMSL_trend(GMSL):\n",
    "    ''' linear fit of a time series '''\n",
    "    trend_params = GMSL.polyfit(dim=\"time\", deg=1, full=True)\n",
    "    GMSL_trend = xr.polyval(coord=GMSL.time, coeffs=trend_params.polyfit_coefficients)\n",
    "\n",
    "    return GMSL_trend, trend_params\n",
    "def download(source, target, redownload_existing=False):\n",
    "    ''' download data into local folder'''\n",
    "    print(target)\n",
    "    print(source)\n",
    "    if not os.path.isfile(target) or redownload_existing==True:\n",
    "        !wget --quiet --continue --output-document $target $source\n",
    "    else:\n",
    "        print('not re-downloading')\n",
    "    return target\n",
    "def download_file(url: str, out: str, force: bool=False):\n",
    "    \"\"\"\n",
    "    url (str): the HTTPS url from which the file will download\n",
    "    out (str): the local path into which the file will download\n",
    "    force (bool): download even if the file exists locally already\n",
    "    \"\"\"\n",
    "    if not isdir(out):\n",
    "        raise Exception(f\"Output directory doesnt exist! ({out})\")\n",
    "    \n",
    "    target_file = join(out, basename(url))\n",
    "    \n",
    "    # if the file has already been downloaded, skip    \n",
    "    if isfile(target_file) and force is False:\n",
    "        print('file exists, and force=False, not re-downloading')\n",
    "        return 0\n",
    "    \n",
    "    with requests.get(url) as r:\n",
    "        if not r.status_code // 100 == 2: \n",
    "            raise Exception(r.text)\n",
    "            return 0\n",
    "        else:\n",
    "            with open(target_file, 'wb') as f:\n",
    "                total_size_in_bytes= int(r.headers.get('content-length', 0))\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "                return total_size_in_bytes\n",
    "# download a list of files\n",
    "def download_files(dls):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # use 12 threads for concurrent downloads\n",
    "    with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "        results = list(tqdm(executor.map(download_file, dls, repeat(download_dir)), total=len(dls)))\n",
    "    \n",
    "        total_download_size_in_bytes = np.sum(np.array(results))\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        print('\\n=====================================')\n",
    "        print(f'total downloaded: {np.round(total_download_size_in_bytes/1e6,2)} Mb')\n",
    "        print(f'avg download speed: {np.round(total_download_size_in_bytes/1e6/total_time,2)} Mb/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define local disk directories\n",
    "\n",
    "Modify the home path in pth_hm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory\n",
    "\n",
    "# change pth_hm to your folder\n",
    "pth_hm='/home/jpluser/Dask_test/'\n",
    "\n",
    "output_dir=Path(pth_hm+'/ECCO_global_mean_TS')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ECCO_grid_dir =Path('/ECCO_grids/')\n",
    "ECCO_grid_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# staging directory\n",
    "download_dir=Path('/ECCO_global_mean_TS/tmp_dl')\n",
    "download_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connect S3 file system\n",
    "\n",
    "Get keys, pass credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import requests\n",
    "\n",
    "def store_aws_keys(endpoint: str=\"https://archive.podaac.earthdata.nasa.gov/s3credentials\"):    \n",
    "    with requests.get(endpoint, \"w\") as r:\n",
    "        accessKeyId, secretAccessKey, sessionToken, expiration = list(r.json().values())\n",
    "\n",
    "    creds ={}\n",
    "    creds['AccessKeyId'] = accessKeyId\n",
    "    creds['SecretAccessKey'] = secretAccessKey\n",
    "    creds['SessionToken'] = sessionToken\n",
    "    creds['expiration'] = expiration\n",
    "    \n",
    "    return creds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_s3():\n",
    "    creds = store_aws_keys()\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        key=creds['AccessKeyId'],\n",
    "        secret=creds['SecretAccessKey'],\n",
    "        token=creds['SessionToken'],\n",
    "        client_kwargs={'region_name':'us-west-2'},\n",
    "    )\n",
    "    print(f\"\\nThe current session token expires at {creds['expiration']}.\\n\")\n",
    "    return s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ECCO grid geometry to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_grid_filename = 'GRID_GEOMETRY_ECCO_V4r4_latlon_0p50deg.nc'\n",
    "ECCO_grid_url = \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/ECCO_L4_GEOMETRY_05DEG_V4R4/\"\n",
    "\n",
    "source = ECCO_grid_url + ECCO_grid_filename\n",
    "target = ECCO_grid_dir / ECCO_grid_filename\n",
    "\n",
    "local_grid_fname = download(source, target)\n",
    "ecco_grid = xr.open_dataset(local_grid_fname)\n",
    "ecco_grid.load()\n",
    "print(ecco_grid.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate ECCO grid cell volumes and total ocean volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area is grid cell area * land/ocean mask\n",
    "# volume is grid cell thickness (drF) * area (rA) * partial cell factors (hFacC) * land/ocean mask (maskC)\n",
    "\n",
    "grid_cell_area = ecco_grid.area * ecco_grid.maskC.isel(Z=0)\n",
    "grid_cell_vol = ecco_grid.drF * ecco_grid.area * ecco_grid.hFacC * ecco_grid.maskC\n",
    "\n",
    "total_grid_cell_area= grid_cell_area.sum()\n",
    "total_grid_cell_area.name = 'Total ECCO ocean area'\n",
    "\n",
    "total_grid_cell_vol = grid_cell_vol.sum()\n",
    "total_grid_cell_vol.name = 'Total ECCO ocean volume'\n",
    "\n",
    "print(f'total grid cell area  {total_grid_cell_area.values/1e9:0.3g} billion km$^2$')\n",
    "print(f'total grid cell volume  {total_grid_cell_vol.values/1e9:0.3g} billion km$^3$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cell_area.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find S3 Addresses to ECCO Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO.DAAC's 'short name' is an identifier for the dataset\n",
    "ShortName = 'ECCO_L4_SSH_05DEG_MONTHLY_V4R4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask PODAAC for the collection id using the 'short name'\n",
    "response = requests.get(\n",
    "    url='https://cmr.earthdata.nasa.gov/search/collections.umm_json', \n",
    "    params={'provider': \"POCLOUD\",\n",
    "            'ShortName': ShortName,\n",
    "            'page_size': 1}\n",
    ")\n",
    "\n",
    "ummc = response.json()['items'][0]\n",
    "ccid = ummc['meta']['concept-id']\n",
    "print(f'collection id: {ccid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob to find the NetCDF files associated with this collection id\n",
    "year = '*'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ss = \"podaac-ops-cumulus-protected/\" + ShortName + '/*'+ str(year) + '*.nc'\n",
    "\n",
    "s3 = refresh_s3()\n",
    "ECCO_s3_files = s3.glob(ss)\n",
    "\n",
    "print(f'time to find urls: { time.time() - start_time} s\\n')\n",
    "\n",
    "# make a list of just the filenames\n",
    "ECCO_files =[]\n",
    "for f in ECCO_s3_files:\n",
    "    ECCO_files.append(f.split('/')[-1])\n",
    "\n",
    "pprint(ECCO_files[0])\n",
    "pprint(ECCO_files[-1])\n",
    "pprint(ECCO_s3_files[0])\n",
    "pprint(ECCO_s3_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of s3 files to urls\n",
    "ECCO_s3_files_as_http = ['https://archive.podaac.earthdata.nasa.gov/' + f for f in ECCO_s3_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method \\#1: Calculate using S3 Direct Access fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_files(ECCO_s3_files_as_http)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct File Access within EC2, parallel=True (Success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "local_files = np.sort(list(download_dir.glob('*nc')))\n",
    "\n",
    "#Total number of granules for the monthly fields of 26 years is 312\n",
    "\n",
    "num_granules = 312\n",
    "\n",
    "ECCO_SSH_ds = xr.open_mfdataset(\n",
    "    paths=local_files[:num_granules],\n",
    "    coords='minimal', \n",
    "    compat='override', \n",
    "    data_vars='minimal',\n",
    "    decode_cf=True,\n",
    "    join='left',\n",
    "    parallel = True\n",
    ")\n",
    "ECCO_SSH_ds.close()\n",
    "\n",
    "tt = time.time() - start_time\n",
    "\n",
    "print(f'open time = {tt:0.3g} s')\n",
    "print(f'open time per granule (n={num_granules}) = {tt/num_granules:0.3g} s \\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "GMSL = compute_GMSL(ECCO_SSH_ds.SSH, ecco_grid.area, total_grid_cell_area)\n",
    "GMSL_trend, trend_params = compute_GMSL_trend(GMSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL.plot()\n",
    "GMSL_trend.plot(color='r')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rough trend: final - initial / length of time series in years\n",
    "GMSL_rough_trend = 1000*(GMSL_trend[-1]-GMSL_trend[0])/(len(GMSL.time)/12)\n",
    "print(f'{np.round(GMSL_rough_trend.values,3)} mm/yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method \\#2 Direct S3 Access, parallel=False\n",
    "\n",
    "parallel must be false else open_mfdataset hangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read num_granules number of files\n",
    "num_granules = 32\n",
    "\n",
    "# update s3 credentials\n",
    "s3 = refresh_s3()\n",
    "\n",
    "# open each file using s3\n",
    "paths=[s3.open(f) for f in ECCO_s3_files[:num_granules]]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ECCO_SSH_ds = xr.open_mfdataset(\n",
    "    paths=paths,\n",
    "    coords='minimal', \n",
    "    compat='override', \n",
    "    data_vars='minimal',\n",
    "    decode_cf=True,\n",
    "    join='left',\n",
    "    parallel=False\n",
    ")\n",
    "ECCO_SSH_ds.close()\n",
    "\n",
    "tt = time.time() - start_time\n",
    "\n",
    "print(f'open time = {tt:0.3g} s')\n",
    "print(f'open time per granule (n={num_granules}) = {tt/num_granules:0.3g} s \\n') \n",
    "\n",
    "## WITH ATTACHED DASK CLUSTER AND PARALLEL=FALSE\n",
    "#===============================================\n",
    "# 3 files  0.4 s (.14 s per)\n",
    "# 12 files 1.7 (.14s per)\n",
    "# 24 files 3.6 (0.15s per)\n",
    "# 36 files 5.4 (0.15s per)\n",
    "# ...\n",
    "# 312 files 54 s (0.18s per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify we got something good \n",
    "pprint(ECCO_SSH_ds.data_vars)\n",
    "pprint(ECCO_SSH_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "GMSL = compute_GMSL(ECCO_SSH_ds['SSH'], ecco_grid.area, total_grid_cell_area)\n",
    "GMSL_trend, GMSL_params = compute_GMSL_trend(GMSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL.plot()\n",
    "GMSL_trend.plot(color='r')\n",
    "plt.grid()\n",
    "\n",
    "# rough trend: (final - initial) / length of time series in years\n",
    "GMSL_rough_trend = 1000*(GMSL_trend[-1]-GMSL_trend[0])/(len(GMSL.time)/12)\n",
    "print(f'rough trend = {np.round(GMSL_rough_trend.values,3)} mm/yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Direct S3 Access, parallel=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ THIS MANY FILES\n",
    "num_granules = 12\n",
    "\n",
    "# update s3 credentials\n",
    "s3 = refresh_s3()\n",
    "\n",
    "# open each file using s3\n",
    "paths=[s3.open(f) for f in ECCO_s3_files[:num_granules]]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# if the files in 'paths' were LOCAL this does work,\n",
    "# when the files are on S3, crashes with error message:\n",
    "\n",
    "#ValueError: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\n",
    "#https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\n",
    "#https://docs.xarray.dev/en/stable/user-guide/io.html\n",
    "\n",
    "ECCO_SSH_ds = xr.open_mfdataset(\n",
    "    paths=paths,\n",
    "    coords='minimal', \n",
    "    compat='override', \n",
    "    data_vars='minimal',\n",
    "    decode_cf=True,\n",
    "    join='left',\n",
    "    parallel=True\n",
    ")\n",
    "ECCO_SSH_ds.close()\n",
    "\n",
    "tt = time.time() - start_time\n",
    "\n",
    "print(f'open time = {tt:0.3g} s')\n",
    "print(f'open time per granule (n={num_granules}) = {tt/num_granules:0.3g} s \\n') \n",
    "\n",
    "## WITH ATTACHED DASK CLUSTER AND PARALLEL=TRUE\n",
    "#===============================================\n",
    "# 3 files  0.4 s (.14 s per)\n",
    "# 12 files 1.7 (.14s per)\n",
    "# 24 files 3.6 (0.15s per)\n",
    "# 36 files 5.4 (0.15s per)\n",
    "# ...\n",
    "# 312 files 54 s (0.18s per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 4: Dask delayed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayed_global_mean(fn, s3, ecco_grid_area, total_grid_cell_area):\n",
    "    \n",
    "    d_start_time = time.time()\n",
    "    \n",
    "# works when we open with open_dataset, dask client, and files on S3\n",
    "    ECCO_SSH_ds = xr.open_dataset(s3.open(fn))    \n",
    "\n",
    "# fails with open_mfdataset, dask client, and files on S3\n",
    "#    ECCO_SSH_ds = xr.open_mfdataset(s3.open(fn))\n",
    "        \n",
    "    GMSL = compute_GMSL(ECCO_SSH_ds['SSH'], ecco_grid_area, total_grid_cell_area)\n",
    "    worker_id = get_worker().id\n",
    "    \n",
    "    tt = time.time() - d_start_time\n",
    "   \n",
    "    return GMSL, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_grid_area= ecco_grid.area\n",
    "from dask import delayed,compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_granules = 312\n",
    "result=[]\n",
    "\n",
    "for fn in ECCO_s3_files[0:num_granules]:\n",
    "    result.append(delayed(delayed_global_mean)(fn, s3, \\\n",
    "                                               ecco_grid_area, total_grid_cell_area) )\n",
    "\n",
    "tt = time.time() - start_time\n",
    "\n",
    "print('append result')\n",
    "print(f'append result time = {tt:0.3g} s')\n",
    " \n",
    "print('calculate')\n",
    "\n",
    "GMSL_delayed =np.array(compute(result)).squeeze()\n",
    "tt = time.time() - start_time\n",
    "\n",
    "print(f'calc time = {tt:0.3g} s')\n",
    "print(f'calc time per granule (n={num_granules}) = {tt/num_granules:0.3g} s \\n') \n",
    "\n",
    "\n",
    "# calculation timing\n",
    "# ==================\n",
    "#  64:  2.7s, 0.0416s per granule\n",
    "# 128:  5.6s, 0.0432s per granule\n",
    "# 312: 13  s, 0.0416s per granule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
